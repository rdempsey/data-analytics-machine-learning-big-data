{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example demonstrates training an elastic net regularized linear regression model and extracting model summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from os import getlogin, path\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home Directory: /Users/robert.dempsey/Dev/daamlobd\n",
      "Data Directory: /Users/robert.dempsey/Dev/daamlobd/data\n",
      "MLlib Data Directory: /Users/robert.dempsey/Dev/daamlobd/data/mllib\n",
      "Data File: /Users/robert.dempsey/Dev/daamlobd/data/mllib/sample_libsvm_data.txt\n"
     ]
    }
   ],
   "source": [
    "# Directories \n",
    "\n",
    "# HOME_DIR = path.join(\"/home\", getlogin())\n",
    "HOME_DIR = path.join(\"/Users/robert.dempsey/Dev/daamlobd\")\n",
    "DATA_DIR = path.join(HOME_DIR, \"data\")\n",
    "MLLIB_DATA_DIR = path.join(DATA_DIR, \"mllib\")\n",
    "DATA_FILE   = path.join(MLLIB_DATA_DIR, \"sample_libsvm_data.txt\")\n",
    "\n",
    "# Check the things\n",
    "print(\"Home Directory: {}\".format(HOME_DIR))\n",
    "print(\"Data Directory: {}\".format(DATA_DIR))\n",
    "print(\"MLlib Data Directory: {}\".format(MLLIB_DATA_DIR))\n",
    "print(\"Data File: {}\".format(DATA_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkContext and a SQLContext context to use\n",
    "sc = SparkContext(appName=\"Naive Bayes Classification with Spark\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the training data\n",
    "data = sqlContext.read.format(\"libsvm\").load(DATA_FILE)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, features=SparseVector(692, {127: 51.0, 128: 159.0, 129: 253.0, 130: 159.0, 131: 50.0, 154: 48.0, 155: 238.0, 156: 252.0, 157: 252.0, 158: 252.0, 159: 237.0, 181: 54.0, 182: 227.0, 183: 253.0, 184: 252.0, 185: 239.0, 186: 233.0, 187: 252.0, 188: 57.0, 189: 6.0, 207: 10.0, 208: 60.0, 209: 224.0, 210: 252.0, 211: 253.0, 212: 252.0, 213: 202.0, 214: 84.0, 215: 252.0, 216: 253.0, 217: 122.0, 235: 163.0, 236: 252.0, 237: 252.0, 238: 252.0, 239: 253.0, 240: 252.0, 241: 252.0, 242: 96.0, 243: 189.0, 244: 253.0, 245: 167.0, 262: 51.0, 263: 238.0, 264: 253.0, 265: 253.0, 266: 190.0, 267: 114.0, 268: 253.0, 269: 228.0, 270: 47.0, 271: 79.0, 272: 255.0, 273: 168.0, 289: 48.0, 290: 238.0, 291: 252.0, 292: 252.0, 293: 179.0, 294: 12.0, 295: 75.0, 296: 121.0, 297: 21.0, 300: 253.0, 301: 243.0, 302: 50.0, 316: 38.0, 317: 165.0, 318: 253.0, 319: 233.0, 320: 208.0, 321: 84.0, 328: 253.0, 329: 252.0, 330: 165.0, 343: 7.0, 344: 178.0, 345: 252.0, 346: 240.0, 347: 71.0, 348: 19.0, 349: 28.0, 356: 253.0, 357: 252.0, 358: 195.0, 371: 57.0, 372: 252.0, 373: 252.0, 374: 63.0, 384: 253.0, 385: 252.0, 386: 195.0, 399: 198.0, 400: 253.0, 401: 190.0, 412: 255.0, 413: 253.0, 414: 196.0, 426: 76.0, 427: 246.0, 428: 252.0, 429: 112.0, 440: 253.0, 441: 252.0, 442: 148.0, 454: 85.0, 455: 252.0, 456: 230.0, 457: 25.0, 466: 7.0, 467: 135.0, 468: 253.0, 469: 186.0, 470: 12.0, 482: 85.0, 483: 252.0, 484: 223.0, 493: 7.0, 494: 131.0, 495: 252.0, 496: 225.0, 497: 71.0, 510: 85.0, 511: 252.0, 512: 145.0, 520: 48.0, 521: 165.0, 522: 252.0, 523: 173.0, 538: 86.0, 539: 253.0, 540: 225.0, 547: 114.0, 548: 238.0, 549: 253.0, 550: 162.0, 566: 85.0, 567: 252.0, 568: 249.0, 569: 146.0, 570: 48.0, 571: 29.0, 572: 85.0, 573: 178.0, 574: 225.0, 575: 253.0, 576: 223.0, 577: 167.0, 578: 56.0, 594: 85.0, 595: 252.0, 596: 252.0, 597: 252.0, 598: 229.0, 599: 215.0, 600: 252.0, 601: 252.0, 602: 252.0, 603: 196.0, 604: 130.0, 622: 28.0, 623: 199.0, 624: 252.0, 625: 252.0, 626: 253.0, 627: 252.0, 628: 252.0, 629: 233.0, 630: 145.0, 651: 25.0, 652: 128.0, 653: 252.0, 654: 253.0, 655: 252.0, 656: 141.0, 657: 37.0}))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[121,122,123...|\n",
      "|  0.0|(692,[122,123,124...|\n",
      "|  0.0|(692,[122,123,148...|\n",
      "|  0.0|(692,[123,124,125...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train and test\n",
    "splits = data.randomSplit([0.6, 0.4], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, features: vector]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes_493e99e4cc7a3b2dbd80\n"
     ]
    }
   ],
   "source": [
    "# Create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "print(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaiveBayes_493e99e4cc7a3b2dbd80\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "nb_model = nb.fit(train)\n",
    "print(nb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "|label|            features|       rawPrediction|probability|prediction|\n",
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "|  0.0|(692,[95,96,97,12...|[-174115.98587057...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[98,99,100,1...|[-178402.52307196...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[100,101,102...|[-100905.88974016...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[-244784.29791241...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[-196900.88506109...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[-238164.45338794...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[124,125,126...|[-184206.87833381...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-214174.52863813...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[-182844.62193963...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[128,129,130...|[-246557.10990301...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-208282.08496711...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[-243457.69885665...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[-260933.50931276...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[-220274.72552901...|  [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[181,182,183...|[-154830.07125175...|  [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[99,100,101,...|[-145978.24563975...|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[100,101,102...|[-147916.32657832...|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[123,124,125...|[-139663.27471685...|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-129013.44238751...|  [0.0,1.0]|       1.0|\n",
      "|  1.0|(692,[125,126,127...|[-81829.799906049...|  [0.0,1.0]|       1.0|\n",
      "+-----+--------------------+--------------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select example rows to display.\n",
    "predictions = nb_model.transform(test)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\",\n",
    "                                              predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close it down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
